{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XmhG0pdpbKwt"
   },
   "source": [
    "# Initial setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all needed packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "xPn94WQkxH32",
    "outputId": "b7b760d9-3e3c-4166-bc37-f4587dff9679"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from six.moves import urllib\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KZHXfZ5IYK8g"
   },
   "outputs": [],
   "source": [
    "from keras import applications\n",
    "preprocess_input = applications.mobilenet_v2.preprocess_input \n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_visible_devices(gpus[1], 'GPU')\n",
    "tf.config.experimental.set_memory_growth(gpus[1], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! unzip ~/Documents/Dataset/binary/trainBN600.zip -d ~/Documents/Dataset/binary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZPkRDGB2f01W"
   },
   "source": [
    "## Set useful paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1I5D0l4P093m"
   },
   "source": [
    "The folder structure is the following: there is a main folder *Dataset* with inside *binary* folder. All elements for the training are in the latter, in particular in two folders *Persona* and *Others* in *path_train*.\n",
    "\n",
    "The class we want to recognize among all is therefore the *target class Persona*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_ds = \"Dataset\"\n",
    "path_binary = os.path.join(path_ds, \"binary\")\n",
    "path_train = os.path.join(path_binary, \"trainBN\")\n",
    "if not os.path.exists(path_train):\n",
    "      os.makedirs(path_train)\n",
    "target = \"Persona\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_train_Persona = os.path.join(path_train, \"Persona\")\n",
    "if not os.path.exists(path_train_Persona):\n",
    "      os.makedirs(path_train_Persona)\n",
    "path_train_Others = os.path.join(path_train, \"Others\")  \n",
    "if not os.path.exists(path_train_Others):\n",
    "      os.makedirs(path_train_Others)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We print how many people images and how many alien images are present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pri1OqimNWI9"
   },
   "outputs": [],
   "source": [
    "print(\"There are \", len(os.listdir(path_train_Persona)), \" images from Target dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"There are \", len(os.listdir(path_train_Others)), \" pre-processed images from class Others\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z4Em_ryk6Eqw"
   },
   "source": [
    "# Training part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5cV-hXFo0Nxa"
   },
   "source": [
    "## Build the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We instantiate a unique MobileNetV2 in *base_model*. MobileNetV2 by Google belongs to MobileNets family, efficient and optimized architectures for mobile devices. It is fast and provides high accuracy, requiring few parameters and low computational power, also compared to previous versions.\n",
    "\n",
    "• We load *weights* pre-trained on ImageNet, without including the default top part with 1000 neurons;\n",
    "\n",
    "• The *input shape* of images is set to (224, 224, 3);\n",
    "\n",
    "• The hyperparameter alpha, belonging to range (0, 1] and known as the width multiplier that determines the number of filters at each layer, is set to its default value 1;\n",
    "\n",
    "• A *global average pooling layer* is inserted after the the last convolutional block, passing from a 4D output tensor of shape (batch_size, 7, 7, 1280) to a flattened 2D output tensor of shape (batch_size, 1280)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 1.0 #for MobileNetV2\n",
    "base_model = applications.MobileNetV2(include_top=False, \n",
    "                                      input_shape=(224, 224, 3), \n",
    "                                      alpha=alpha, \n",
    "                                      weights='imagenet',\n",
    "                                      pooling=\"avg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• A *fully connected layer* with one neuron and therefore a sigmoid activation function is attached, in order to compute binary predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = Dense(1, activation='sigmoid')(base_model.output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The keras model is defined, having:\n",
    "\n",
    "• 1 input, the base model input that is an image batch of size (batch_size, 224, 224, 3);\n",
    "\n",
    "• 1 output, the binary classification outcome. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Model(inputs=base_model.input, outputs = predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We print the output shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.output) #shape=(None, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We visualize properties of all layers that are part of the model and their number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "OfUwoNHy0ZM8",
    "outputId": "bf0866fc-80a9-4873-8499-baad2e77e8f4"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of layers in the base model: \", len(base_model.layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of layers in the model: \", len(model.layers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the training phase some layers of the network are *frozen*, to preserve\n",
    "imported parameters pre-trained on ImageNet. This means we take low-level\n",
    "features learned in a different classification task, by leveraging them\n",
    "in our problem.\n",
    "\n",
    "In MobileNetV2 we choose to initially freeze all blocks until block 13, having 40 unfrozen layers over the whole 157 layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fixed weights\n",
    "for layer in model.layers:\n",
    "    if layer.name == \"block_13_expand\": # \"block5_conv1\": for VGG16\n",
    "        break\n",
    "    else:\n",
    "        layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3GC9XJnLKCRo"
   },
   "outputs": [],
   "source": [
    "#model.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=0\n",
    "for layer in model.layers:\n",
    "    #print(layer, layer.trainable)\n",
    "    if layer.trainable == True:\n",
    "        k=k+1\n",
    "print(\"Layers with trainable=True: \", k, \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "4NKThhJKJwL1",
    "outputId": "95d33389-f92a-4660-c611-2c646310f4f2"
   },
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "    print(layer, layer.trainable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AgWpq37tsu1i"
   },
   "source": [
    "## Compile the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is compiled defining:\n",
    "\n",
    "• the *batch_size* of the input batch composed by images from the two classes;\n",
    "\n",
    "• the *optimizer* as the gradient descent algorithm, employed with a very\n",
    "low learning rate lr = 0.00005 and a weight decay of 0.00005;\n",
    "\n",
    "• the loss as the *binary crossentropy*, consistent with network output;\n",
    "\n",
    "• the monitored metric as the *accuracy*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rYG2YtpFR52L"
   },
   "outputs": [],
   "source": [
    "#batch_size = 256 \n",
    "batch_size = 32 \n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.SGD(learning_rate=0.00005, decay=0.00005), #, momentum=0.9),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fO-yyonln9D2"
   },
   "source": [
    "## Create th ImageDataGenerator object for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf `find -type d -name .ipynb_checkpoints`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_imgen = ImageDataGenerator(preprocessing_function = preprocess_input)\n",
    "\n",
    "gen1 = input_imgen.flow_from_directory(path_train,\n",
    "                                        target_size = (224 ,224),\n",
    "                                        class_mode = 'binary',\n",
    "                                        batch_size = batch_size,\n",
    "                                        shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gen1.class_indices)   #{'Others': 0, 'Persona': 1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Epochs are delineated from the size of the target dataset.\n",
    "\n",
    "The number of epochs is set to 400, taking care to save intermediate models every 50 epochs to properly study the evolution of tested metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JJpo52KIiERr"
   },
   "outputs": [],
   "source": [
    "train_size = len(os.listdir(path_train_Persona)) #6000\n",
    "epochs = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "x2P9Y4ycp7xD",
    "outputId": "f8457179-bdfd-4b72-89a5-6f7223000ad8"
   },
   "outputs": [],
   "source": [
    "print(train_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZfuUYe8vKVOD"
   },
   "source": [
    "## Train with *fit*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 138
    },
    "colab_type": "code",
    "id": "W5Iy71hdohG6",
    "outputId": "afeaef6f-37ac-43ff-f3b6-a3047bce8fe5"
   },
   "outputs": [],
   "source": [
    "history = model.fit(gen1,\n",
    "                    epochs = epochs,\n",
    "                    steps_per_epoch = train_size // batch_size,\n",
    "                    #use_multiprocessing=True,\n",
    "                    #shuffle=False\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "vmo0848ApZul",
    "outputId": "c6a87a02-5f50-4045-9e53-d03bd5d1a7d8"
   },
   "outputs": [],
   "source": [
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qfwq2QV1HWoE"
   },
   "source": [
    "Retrive losses and accuracy from history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 229
    },
    "colab_type": "code",
    "id": "tw9b2A7kpfjs",
    "outputId": "54310e5f-49f5-4e0d-9f1b-51b3143dc7d9"
   },
   "outputs": [],
   "source": [
    "# Retrieve losses and accuracy\n",
    "final_loss = history.history['loss']\n",
    "acc = history.history['dense_accuracy']\n",
    "\n",
    "# Get number of epochs\n",
    "epochs = range(len(total_loss))\n",
    "\n",
    "print(\"Loss = \", final_loss)\n",
    "print(\"Accuracy (dense) = \", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IG-97lPXJx86"
   },
   "source": [
    "## Train with *train_on_batch* (suggested)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, values of losses are stored every 10 batch iterations, in order to understand what happens during each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4lXTCsB4Wb0H"
   },
   "outputs": [],
   "source": [
    "final_loss = final_loss\n",
    "acc = acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_loss= []\n",
    "acc= []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "MyAkXmR8-Bam",
    "outputId": "e9cca722-9caa-4f27-cf7d-545051228804",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_batches = train_size // batch_size\n",
    "print(\"Number of batches : \", n_batches)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(\"\\nEpoch \", epoch+1 , \"/\", epochs)\n",
    "  \n",
    "    for i in range(n_batches):\n",
    "        print(\"Processing batch...  \", i)\n",
    "        batch = next(gen1)\n",
    "        #print(type(batch), batch[0].shape, batch[1].shape)\n",
    "        loss, accuracy = model.train_on_batch(batch[0], batch[1])\n",
    "        #Print the total loss every 10 iterations\n",
    "        if i % 10 == 0:\n",
    "            print(\"\\nLoss after iteration \", i, \" is \", loss)\n",
    "            final_loss.append(loss)\n",
    "            acc.append(accuracy)\n",
    "    if (epoch+1) % 50 == 0:\n",
    "        my_model = \"my_model_binary4000_\"+ str(epoch+1) +\".h5\"\n",
    "        path_model = os.path.join(path_ds, my_model)  #/content/drive/My Drive/my_model.h5\n",
    "        model.save(path_model)\n",
    "\n",
    "    print(\"Loss at the end of epoch \" , epoch+1, \": \", loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gPfNG2afDVw5"
   },
   "source": [
    "## Retrieve losses stored in folder *Dataset* if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Kye2EVaQkYKK"
   },
   "outputs": [],
   "source": [
    "path_loss = os.path.join(path_ds, \"loss19.json\") \n",
    "path_lc = os.path.join(path_ds, \"l_c19.json\")\n",
    "path_ld = os.path.join(path_ds, \"l_d19.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ygJ3x3ZtC5E2"
   },
   "outputs": [],
   "source": [
    "with open(path_loss, 'r') as fp:\n",
    "    total_loss = json.load(fp)\n",
    "with open(path_lc, 'r') as fp:\n",
    "    l_c = json.load(fp)\n",
    "with open(path_ld, 'r') as fp:\n",
    "    l_d = json.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ADu3kHEuCDI3"
   },
   "source": [
    "## Plot loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "7RxdBw2fbpbV",
    "outputId": "65fa9c04-b6ee-4311-b7db-464a2f81b070"
   },
   "outputs": [],
   "source": [
    "print(np.min(final_loss))\n",
    "print(np.max(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot loss and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "colab_type": "code",
    "id": "TVVII35ZHJab",
    "outputId": "a5456385-224a-42a6-87c9-b7d7e32d9248",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(final_loss, label=\"Loss\")\n",
    "plt.plot(acc, label=\"Accuracy\")\n",
    "plt.xlabel(\"training steps\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "colab_type": "code",
    "id": "K4fKOmOYrHG_",
    "outputId": "37e236ad-0ad4-4931-d4ce-9a660b3f35db"
   },
   "outputs": [],
   "source": [
    "plt.plot(final_loss, label=\"Loss\")\n",
    "plt.xlabel(\"training steps\")\n",
    "plt.legend()\n",
    "#plt.xscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "colab_type": "code",
    "id": "sTbODn2SrLJw",
    "outputId": "d480229f-89c3-4afe-d21d-0a11c408f4a2",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(acc, label=\"Accuracy\")\n",
    "plt.xlabel(\"training steps\")\n",
    "#plt.xscale('log')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "msgsUxHQCL7d"
   },
   "source": [
    "## Save losses on folder *Dataset* if needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aeEPVeMhvy0B"
   },
   "outputs": [],
   "source": [
    "path_loss = os.path.join(path_ds, \"loss20.json\") #/content/drive/My Drive/loss.json\n",
    "path_lc = os.path.join(path_ds, \"l_c20.json\")\n",
    "path_ld = os.path.join(path_ds, \"l_d20.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F9UvdqTGwDcb"
   },
   "outputs": [],
   "source": [
    "with open(path_loss, 'w') as fp:\n",
    "    json.dump(total_loss, fp)\n",
    "with open(path_lc, 'w') as fp:\n",
    "    json.dump(l_c, fp)\n",
    "with open(path_ld, 'w') as fp:\n",
    "    json.dump(l_d, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bt2fyXNzrnvQ"
   },
   "source": [
    "## Save trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MfhgC_h1rpa3"
   },
   "outputs": [],
   "source": [
    "path_model = os.path.join(path_ds, \"my_modelbin_200.h5\")  #/content/drive/My Drive/my_model.h5\n",
    "model.save(path_model)  # creates a HDF5 file 'my_model.h5'\n",
    "#del model  # deletes the existing model"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "cr2RSJ4WQSE4",
    "5cV-hXFo0Nxa",
    "6t_i7A2IsktS",
    "PksJfQ1JbEIv",
    "A-sZmgmSeOCh",
    "msgsUxHQCL7d",
    "C7WPqyAvVQd6",
    "h0dRXypAMxo2",
    "XFU_0t0dflTg",
    "R8VBaCYBloF2"
   ],
   "name": "training_new_approach.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "TF2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
